{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:00:00.445741Z",
     "iopub.status.busy": "2025-03-05T22:00:00.445459Z",
     "iopub.status.idle": "2025-03-05T22:00:03.883432Z",
     "shell.execute_reply": "2025-03-05T22:00:03.882540Z",
     "shell.execute_reply.started": "2025-03-05T22:00:00.445717Z"
    },
    "papermill": {
     "duration": 3.162776,
     "end_time": "2025-02-09T16:49:30.038472",
     "exception": false,
     "start_time": "2025-02-09T16:49:26.875696",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:00:03.885180Z",
     "iopub.status.busy": "2025-03-05T22:00:03.884692Z",
     "iopub.status.idle": "2025-03-05T22:00:04.774211Z",
     "shell.execute_reply": "2025-03-05T22:00:04.773275Z",
     "shell.execute_reply.started": "2025-03-05T22:00:03.885148Z"
    },
    "papermill": {
     "duration": 1.784209,
     "end_time": "2025-02-09T16:49:31.826758",
     "exception": false,
     "start_time": "2025-02-09T16:49:30.042549",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch import nn, optim, tensor, Tensor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:00:04.776009Z",
     "iopub.status.busy": "2025-03-05T22:00:04.775553Z",
     "iopub.status.idle": "2025-03-05T22:00:04.784736Z",
     "shell.execute_reply": "2025-03-05T22:00:04.783953Z",
     "shell.execute_reply.started": "2025-03-05T22:00:04.775985Z"
    },
    "papermill": {
     "duration": 0.01366,
     "end_time": "2025-02-09T16:49:31.844381",
     "exception": false,
     "start_time": "2025-02-09T16:49:31.830721",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "random.seed(52)\n",
    "torch.manual_seed(52)\n",
    "np.random.seed(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:00:04.786318Z",
     "iopub.status.busy": "2025-03-05T22:00:04.785964Z",
     "iopub.status.idle": "2025-03-05T22:00:04.802608Z",
     "shell.execute_reply": "2025-03-05T22:00:04.801527Z",
     "shell.execute_reply.started": "2025-03-05T22:00:04.786282Z"
    },
    "papermill": {
     "duration": 0.022849,
     "end_time": "2025-02-09T16:49:31.870643",
     "exception": false,
     "start_time": "2025-02-09T16:49:31.847794",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CandlesDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, years: list, window_size: int, max_samples: int, device):\n",
    "        self.device = device\n",
    "        self.window_size = window_size\n",
    "        self.tables_list = self.__get_correct_tables(root_dir, years)\n",
    "        self.samples = self.__generate_samples(self.tables_list, max_samples)\n",
    "        self.scaled_samples = self.__scale_samples()\n",
    "\n",
    "    def __get_correct_tables(self, root_dir, years):\n",
    "        \"\"\"\n",
    "        get paths of .csv with len > window_size \n",
    "        \"\"\"\n",
    "        tables_list = []\n",
    "        tables_dirs = []\n",
    "        for root, dirs, files in os.walk(root_dir):\n",
    "            if dirs:\n",
    "                tables_dirs = dirs\n",
    "                break\n",
    "        for table_dir in tables_dirs:\n",
    "            if int(table_dir[-4:]) in years:\n",
    "                full_dir = os.path.join(root_dir, table_dir)\n",
    "                for root, dirs, files in os.walk(full_dir):\n",
    "                    for file in files:\n",
    "                        if file.lower().endswith('.csv'):\n",
    "                            full_path = os.path.join(full_dir, file)\n",
    "                            with open(full_path) as f:\n",
    "                                if sum(1 for line in f) > self.window_size:\n",
    "                                    tables_list.append(full_path)\n",
    "        random.shuffle(tables_list)\n",
    "        return tables_list\n",
    "\n",
    "    def __generate_samples(self, tables_list, max_samples):\n",
    "        samples = torch.empty((0, self.window_size + 1, 8)) #(n_blocks, window_size, n_features)\n",
    "        for table in tqdm(tables_list, desc=\"tables done\"):\n",
    "            df = pd.read_csv(\n",
    "                table,\n",
    "                sep =\";\",\n",
    "                names=[\"figi\", \"utc\", \"open\", \"close\", \"high\", \"low\", \"volume\"],\n",
    "                index_col=False\n",
    "                )\n",
    "            df['utc'] = pd.to_datetime(df['utc'], utc=True)\n",
    "\n",
    "            #fill missing candles\n",
    "            df = df.set_index('utc').resample('min').asfreq()\n",
    "            df['volume'] = df['volume'].fillna(0)\n",
    "            for col in ['figi', 'open', 'close', 'high', 'low']:\n",
    "                df[col] = df[col].ffill()\n",
    "\n",
    "            df.drop(labels=['figi'], axis=1, inplace=True)\n",
    "\n",
    "            df = df.resample('5min').agg({ #form 5 minutes candles\n",
    "                    'open': 'first',\n",
    "                    'close': 'last',\n",
    "                    'high': 'max',\n",
    "                    'low': 'min',\n",
    "                    'volume': 'sum'\n",
    "            })\n",
    "\n",
    "            #add time data\n",
    "            df['hour'] = df.index.hour\n",
    "            df['day_of_week'] = df.index.day_of_week\n",
    "            df['minute'] = df.index.minute\n",
    "            df = df[(df['day_of_week'] < 5)] #drop not tradeble days\n",
    "            \n",
    "            data = df.values\n",
    "            if data.shape[0] == 0:\n",
    "                continue\n",
    "            windows = np.lib.stride_tricks.sliding_window_view(\n",
    "                data, (self.window_size + 1, data.shape[1])\n",
    "            )  #(n_blocks, window_size, n_features)\n",
    "            tensor = torch.tensor(windows, dtype=torch.float32).squeeze(dim=1)\n",
    "            samples = torch.vstack([samples, tensor])\n",
    "            if samples.shape[0] > max_samples:\n",
    "                break\n",
    "        return samples\n",
    "\n",
    "    def __scale_samples(self):\n",
    "        stds = self.samples[:, :self.window_size-1, :-3].std(dim=1)\n",
    "        valid_mask = (stds > 1e-7).all(dim=1)\n",
    "        self.samples = self.samples[valid_mask]\n",
    "        mean = self.samples[:, :(self.window_size-1), :-3].mean(dim=1, keepdim=True)\n",
    "        std = self.samples[:, :(self.window_size-1), :-3].std(dim=1, keepdim=True)\n",
    "        epsilon = 1e-7\n",
    "        normalized_data = (self.samples[:, :, :-3] - mean) / (std + epsilon)\n",
    "        normalized_data = torch.cat([normalized_data, self.samples[:, :, -3:]], dim=-1)\n",
    "        normalized_data[..., -3] = normalized_data[..., -3] / 23\n",
    "        normalized_data[..., -2] = normalized_data[..., -2] / 4 \n",
    "        normalized_data[..., -1] = normalized_data[..., -1] / 59\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        return normalized_data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scaled_samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.scaled_samples[idx][:-1, :]\n",
    "        target = self.samples[idx][-1:, :5].squeeze(dim=0)\n",
    "        target = ((target[1] / target[0]) > 1.001).float() # close > open more than commision\n",
    "        return feature, target, self.std[idx], self.mean[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:00:04.803886Z",
     "iopub.status.busy": "2025-03-05T22:00:04.803563Z",
     "iopub.status.idle": "2025-03-05T22:00:04.821519Z",
     "shell.execute_reply": "2025-03-05T22:00:04.820670Z",
     "shell.execute_reply.started": "2025-03-05T22:00:04.803857Z"
    },
    "papermill": {
     "duration": 0.010376,
     "end_time": "2025-02-09T16:49:31.884479",
     "exception": false,
     "start_time": "2025-02-09T16:49:31.874103",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('model_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "heads = config['heads']\n",
    "encoder_layers = config['encoder_layers']\n",
    "d_model = config['d_model']\n",
    "window_size = config['window_size']\n",
    "batch_size = config['batch_size']\n",
    "root_dir = config['data_dir']\n",
    "max_samples_train = config['max_samples_train']\n",
    "max_samples_val = config['max_samples_val']\n",
    "years_train = config['years_train']\n",
    "years_val = config['years_val']\n",
    "max_epoch = config['max_epoch']\n",
    "model_dir = config['model_path']\n",
    "is_preload = config['is_preload']\n",
    "\n",
    "num_workers = 4\n",
    "model_path = os.path.join(model_dir, 'best.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:00:04.822679Z",
     "iopub.status.busy": "2025-03-05T22:00:04.822397Z",
     "iopub.status.idle": "2025-03-05T22:08:37.244929Z",
     "shell.execute_reply": "2025-03-05T22:08:37.243977Z",
     "shell.execute_reply.started": "2025-03-05T22:00:04.822653Z"
    },
    "papermill": {
     "duration": 1350.548196,
     "end_time": "2025-02-09T17:12:02.436054",
     "exception": false,
     "start_time": "2025-02-09T16:49:31.887858",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CandlesDataset(\n",
    "    root_dir=root_dir, \n",
    "    years=years_train, \n",
    "    window_size=window_size,\n",
    "    max_samples=max_samples_train, \n",
    "    device=device\n",
    "    )\n",
    "\n",
    "val_dataset = CandlesDataset(\n",
    "    root_dir=root_dir, \n",
    "    years=years_val, \n",
    "    window_size=window_size,\n",
    "    max_samples=max_samples_val, \n",
    "    device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:08:37.246181Z",
     "iopub.status.busy": "2025-03-05T22:08:37.245882Z",
     "iopub.status.idle": "2025-03-05T22:08:37.250937Z",
     "shell.execute_reply": "2025-03-05T22:08:37.250181Z",
     "shell.execute_reply.started": "2025-03-05T22:08:37.246150Z"
    },
    "papermill": {
     "duration": 0.062055,
     "end_time": "2025-02-09T17:12:02.555661",
     "exception": false,
     "start_time": "2025-02-09T17:12:02.493606",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:08:37.253522Z",
     "iopub.status.busy": "2025-03-05T22:08:37.253289Z",
     "iopub.status.idle": "2025-03-05T22:08:37.271707Z",
     "shell.execute_reply": "2025-03-05T22:08:37.271057Z",
     "shell.execute_reply.started": "2025-03-05T22:08:37.253495Z"
    },
    "papermill": {
     "duration": 0.063,
     "end_time": "2025-02-09T17:12:02.675135",
     "exception": false,
     "start_time": "2025-02-09T17:12:02.612135",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TimeEncoder(nn.Module):\n",
    "    def __init__(self, candles_features: int, time_features: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(candles_features, d_model)\n",
    "        self.time2vec = nn.Sequential(\n",
    "            nn.Linear(time_features, 32),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(32, d_model)\n",
    "        )\n",
    "        self.learnable_pe = nn.Parameter(torch.randn(1, 5000, d_model))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, time_features = x[:, :, :5], x[:, :, 5:]\n",
    "        t_emb = self.time2vec(time_features)\n",
    "        x = self.input_proj(x)\n",
    "        x = x + self.learnable_pe[:, :x.size(1), :] + t_emb\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:08:37.272869Z",
     "iopub.status.busy": "2025-03-05T22:08:37.272623Z",
     "iopub.status.idle": "2025-03-05T22:08:37.292912Z",
     "shell.execute_reply": "2025-03-05T22:08:37.292097Z",
     "shell.execute_reply.started": "2025-03-05T22:08:37.272847Z"
    },
    "papermill": {
     "duration": 0.062331,
     "end_time": "2025-02-09T17:12:02.794094",
     "exception": false,
     "start_time": "2025-02-09T17:12:02.731763",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model: int, nhead: int, encoder_layers: int):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, nhead, batch_first=True),\n",
    "            num_layers=encoder_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x).mean(dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:08:37.293956Z",
     "iopub.status.busy": "2025-03-05T22:08:37.293702Z",
     "iopub.status.idle": "2025-03-05T22:08:37.308406Z",
     "shell.execute_reply": "2025-03-05T22:08:37.307624Z",
     "shell.execute_reply.started": "2025-03-05T22:08:37.293935Z"
    },
    "papermill": {
     "duration": 0.06372,
     "end_time": "2025-02-09T17:12:02.913719",
     "exception": false,
     "start_time": "2025-02-09T17:12:02.849999",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CandleTransformer(nn.Module):\n",
    "    def __init__(self, heads: int, encoder_layers: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.time_enc = TimeEncoder(candles_features=5, time_features=3, d_model=d_model)\n",
    "        self.transformer = Transformer(d_model=d_model, nhead=heads, encoder_layers=encoder_layers)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(d_model, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.time_enc(x)\n",
    "        trans_out = self.transformer(x)\n",
    "        out = self.out(trans_out)\n",
    "        return out, torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:08:37.309403Z",
     "iopub.status.busy": "2025-03-05T22:08:37.309148Z",
     "iopub.status.idle": "2025-03-05T22:08:56.838979Z",
     "shell.execute_reply": "2025-03-05T22:08:56.838195Z",
     "shell.execute_reply.started": "2025-03-05T22:08:37.309374Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "targets = []\n",
    "for i in tqdm(train_dataset):\n",
    "    targets.append(int(i[1]))\n",
    "weight = torch.tensor(targets.count(0) / targets.count(1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:08:56.840221Z",
     "iopub.status.busy": "2025-03-05T22:08:56.839908Z",
     "iopub.status.idle": "2025-03-05T22:08:59.040394Z",
     "shell.execute_reply": "2025-03-05T22:08:59.039398Z",
     "shell.execute_reply.started": "2025-03-05T22:08:56.840190Z"
    },
    "papermill": {
     "duration": 3.507808,
     "end_time": "2025-02-09T17:12:07.216037",
     "exception": false,
     "start_time": "2025-02-09T17:12:03.708229",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = CandleTransformer(\n",
    "    heads=heads,\n",
    "    encoder_layers=encoder_layers, \n",
    "    d_model=d_model,\n",
    "    ).to(device=device)\n",
    "\n",
    "weights = torch.tensor([weight]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=100,\n",
    "    T_mult=2,\n",
    "    eta_min=1e-6 \n",
    ")\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T22:08:59.041774Z",
     "iopub.status.busy": "2025-03-05T22:08:59.041303Z"
    },
    "papermill": {
     "duration": 5561.933484,
     "end_time": "2025-02-09T18:44:49.207906",
     "exception": false,
     "start_time": "2025-02-09T17:12:07.274422",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "all_f1 = []\n",
    "all_accuracy = []\n",
    "current_epoch = 0\n",
    "\n",
    "if is_preload:\n",
    "    checkpoint = torch.load(model_path, weights_only=True)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    current_epoch = checkpoint['epoch']\n",
    "    train_losses = checkpoint['train_losses']\n",
    "    val_losses = checkpoint['val_losses']\n",
    "    all_f1 = checkpoint['all_f1']\n",
    "    all_accuracy = checkpoint['all_accuracy']\n",
    "    print('Preload model')\n",
    "\n",
    "for epoch in range(current_epoch, max_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for features, targets, _, _  in tqdm(train_loader, desc=f\"Train Epoch {epoch + 1}\"):\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, outputs_proba = model(features)\n",
    "        loss = criterion(outputs.squeeze(dim=1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item() * features.size(0)\n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    for features, targets, _ , _ in tqdm(val_loader, desc=f\"Validation Epoch {epoch + 1}\"):\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "        outputs, outputs_proba = model(features)\n",
    "        val_running_loss += criterion(outputs.squeeze(dim=1), targets).item() * features.size(0)\n",
    "        all_preds.append(outputs_proba.detach().cpu())\n",
    "        all_targets.append(targets.detach().cpu())\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_preds = (all_preds >= 0.5).int()\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    val_loss = val_running_loss / len(val_dataset)\n",
    "\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'all_f1': all_f1,\n",
    "        'all_accuracy': all_accuracy\n",
    "        }, os.path.join(model_dir, f'baseline_{epoch}.tar'))\n",
    "    if len(val_losses) == 0 or val_loss < min(val_losses):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'all_f1': all_f1,\n",
    "            'all_accuracy': all_accuracy\n",
    "            }, os.path.join(model_dir, f'best.tar'))\n",
    "        \n",
    "\n",
    "    f1 = f1_score(all_preds, all_targets)\n",
    "    accuracy = accuracy_score(all_preds, all_targets)\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'LR: {current_lr:.4e}')\n",
    "    print(f\"Epoch {epoch+1}/{max_epoch}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Val f1: {f1:.4f}\")\n",
    "    print(f\"Val accuracy: {accuracy:.4f}\\n\")\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    all_f1.append(f1)\n",
    "    all_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(val_losses, '-o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('BCELoss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.808778,
     "end_time": "2025-02-09T18:44:50.867664",
     "exception": false,
     "start_time": "2025-02-09T18:44:50.058886",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('Min validation loss: ', min(val_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.711042,
     "end_time": "2025-02-09T18:44:55.102448",
     "exception": false,
     "start_time": "2025-02-09T18:44:53.391406",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_counter = 10\n",
    "dataloader = DataLoader(val_dataset, batch_size=1, num_workers=num_workers, shuffle=True)\n",
    "counter = 0\n",
    "for features, targets, std, mean in dataloader:\n",
    "    features, targets, std, mean = features.to(device), targets.to(device), std.to(device), mean.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(features)[0].detach()\n",
    "    print(f\"Target: \", (targets).cpu())\n",
    "    print(f\"Output: \", (outputs >= 0.5).float().cpu())\n",
    "    print()\n",
    "    counter += 1\n",
    "    if counter == max_counter:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6607307,
     "sourceId": 10732446,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6934.28656,
   "end_time": "2025-02-09T18:44:58.664370",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-09T16:49:24.377810",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
