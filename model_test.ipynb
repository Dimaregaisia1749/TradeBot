{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f76aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T16:49:26.880997Z",
     "iopub.status.busy": "2025-02-09T16:49:26.880683Z",
     "iopub.status.idle": "2025-02-09T16:49:30.037195Z",
     "shell.execute_reply": "2025-02-09T16:49:30.036233Z"
    },
    "papermill": {
     "duration": 3.162776,
     "end_time": "2025-02-09T16:49:30.038472",
     "exception": false,
     "start_time": "2025-02-09T16:49:26.875696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f746d29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T16:49:30.047282Z",
     "iopub.status.busy": "2025-02-09T16:49:30.046933Z",
     "iopub.status.idle": "2025-02-09T16:49:31.824944Z",
     "shell.execute_reply": "2025-02-09T16:49:31.824022Z"
    },
    "papermill": {
     "duration": 1.784209,
     "end_time": "2025-02-09T16:49:31.826758",
     "exception": false,
     "start_time": "2025-02-09T16:49:30.042549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch import nn, optim, tensor, Tensor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0264b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T16:49:31.835441Z",
     "iopub.status.busy": "2025-02-09T16:49:31.834903Z",
     "iopub.status.idle": "2025-02-09T16:49:31.843042Z",
     "shell.execute_reply": "2025-02-09T16:49:31.842225Z"
    },
    "papermill": {
     "duration": 0.01366,
     "end_time": "2025-02-09T16:49:31.844381",
     "exception": false,
     "start_time": "2025-02-09T16:49:31.830721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(52)\n",
    "torch.manual_seed(52)\n",
    "np.random.seed(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27259d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T16:49:31.852229Z",
     "iopub.status.busy": "2025-02-09T16:49:31.851909Z",
     "iopub.status.idle": "2025-02-09T16:49:31.869453Z",
     "shell.execute_reply": "2025-02-09T16:49:31.868738Z"
    },
    "papermill": {
     "duration": 0.022849,
     "end_time": "2025-02-09T16:49:31.870643",
     "exception": false,
     "start_time": "2025-02-09T16:49:31.847794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CandlesDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, years: list, window_size: int, max_samples: int, device):\n",
    "        self.device = device\n",
    "        self.window_size = window_size\n",
    "        self.tables_list = self.__get_correct_tables(root_dir, years)\n",
    "        self.samples = self.__generate_samples(self.tables_list, max_samples)\n",
    "        self.scaled_samples = self.__scale_samples()\n",
    "\n",
    "    def __get_correct_tables(self, root_dir, years):\n",
    "        \"\"\"\n",
    "        get paths of .csv with len > window_size \n",
    "        \"\"\"\n",
    "        tables_list = []\n",
    "        for root, dirs, files in os.walk(root_dir):\n",
    "            if dirs:\n",
    "                tables_dirs = dirs\n",
    "                break\n",
    "        for table_dir in tables_dirs:\n",
    "            if int(table_dir[-4:]) in years:\n",
    "                full_dir = os.path.join(root_dir, table_dir)\n",
    "                for root, dirs, files in os.walk(full_dir):\n",
    "                    for file in files:\n",
    "                        if file.lower().endswith('.csv'):\n",
    "                            full_path = os.path.join(full_dir, file)\n",
    "                            with open(full_path) as f:\n",
    "                                if sum(1 for line in f) > self.window_size:\n",
    "                                    tables_list.append(full_path)\n",
    "        random.shuffle(tables_list)\n",
    "        return tables_list\n",
    "\n",
    "    def __generate_samples(self, tables_list, max_samples):\n",
    "        samples = torch.empty((0, self.window_size + 1, 8)) #(n_blocks, window_size, n_features)\n",
    "        for table in tqdm(tables_list, desc=\"tables done\"):\n",
    "            df = pd.read_csv(\n",
    "                table,\n",
    "                sep =\";\",\n",
    "                names=[\"figi\", \"utc\", \"open\", \"close\", \"high\", \"low\", \"volume\"],\n",
    "                index_col=False\n",
    "                )\n",
    "            df['utc'] = pd.to_datetime(df['utc'], utc=True)\n",
    "\n",
    "            #fill missing candles\n",
    "            df = df.set_index('utc').resample('min').asfreq()\n",
    "            df['volume'] = df['volume'].fillna(0)\n",
    "            for col in ['figi', 'open', 'close', 'high', 'low']:\n",
    "                df[col] = df[col].ffill()\n",
    "\n",
    "            #add time data\n",
    "            df['hour'] = df.index.hour\n",
    "            df['day_of_week'] = df.index.day_of_week\n",
    "            df['minute'] = df.index.minute\n",
    "            df.drop(labels=['figi'], axis=1, inplace=True)\n",
    "\n",
    "            df = df[(df['day_of_week'] < 5)] #drop not tradeble days\n",
    "            data = df.values\n",
    "            if data.shape[0] == 0:\n",
    "                continue\n",
    "            windows = np.lib.stride_tricks.sliding_window_view(\n",
    "                data, (self.window_size + 1, data.shape[1])\n",
    "            )  #(n_blocks, window_size, n_features)\n",
    "            tensor = torch.tensor(windows, dtype=torch.float32).squeeze(dim=1)\n",
    "            samples = torch.vstack([samples, tensor])\n",
    "            if samples.shape[0] > max_samples:\n",
    "                break\n",
    "        return samples\n",
    "\n",
    "    def __scale_samples(self):\n",
    "        stds = self.samples[:, :self.window_size-1, :-3].std(dim=1)\n",
    "        valid_mask = (stds > 1e-7).all(dim=1)\n",
    "        self.samples = self.samples[valid_mask]\n",
    "        mean = self.samples[:, :(self.window_size-1), :-3].mean(dim=1, keepdim=True)\n",
    "        std = self.samples[:, :(self.window_size-1), :-3].std(dim=1, keepdim=True)\n",
    "        epsilon = 1e-7\n",
    "        normalized_data = (self.samples[:, :, :-3] - mean) / (std + epsilon)\n",
    "        normalized_data = torch.cat([normalized_data, self.samples[:, :, -3:]], dim=-1)\n",
    "        normalized_data[..., -3] = normalized_data[..., -3] / 23\n",
    "        normalized_data[..., -2] = normalized_data[..., -2] / 6 \n",
    "        normalized_data[..., -1] = normalized_data[..., -1] / 59\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        return normalized_data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scaled_samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.scaled_samples[idx]\n",
    "        return sample[:-1, :], sample[-1:, :5].squeeze(dim=0), self.std[idx], self.mean[idx]#feature, target, std, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d4845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T16:49:31.878341Z",
     "iopub.status.busy": "2025-02-09T16:49:31.878041Z",
     "iopub.status.idle": "2025-02-09T16:49:31.883228Z",
     "shell.execute_reply": "2025-02-09T16:49:31.882425Z"
    },
    "papermill": {
     "duration": 0.010376,
     "end_time": "2025-02-09T16:49:31.884479",
     "exception": false,
     "start_time": "2025-02-09T16:49:31.874103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "heads = 4\n",
    "encoder_layers = 3\n",
    "d_model = 128\n",
    "batch_size = 512\n",
    "window_size = 240\n",
    "num_workers = 4\n",
    "root_dir = 'market_data/unzip_data'\n",
    "model_dir = 'checkpoints/'\n",
    "max_samples_train = 1000000\n",
    "max_samples_val = 200000\n",
    "max_epoch = 10\n",
    "years_train = [2023]\n",
    "years_val = [2024]\n",
    "model_path = os.path.join(model_dir, 'best.tar')\n",
    "is_preload = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3517720a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T16:49:31.892005Z",
     "iopub.status.busy": "2025-02-09T16:49:31.891748Z",
     "iopub.status.idle": "2025-02-09T17:12:02.434613Z",
     "shell.execute_reply": "2025-02-09T17:12:02.433872Z"
    },
    "papermill": {
     "duration": 1350.548196,
     "end_time": "2025-02-09T17:12:02.436054",
     "exception": false,
     "start_time": "2025-02-09T16:49:31.887858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CandlesDataset(\n",
    "    root_dir=root_dir, \n",
    "    years=years_train, \n",
    "    window_size=window_size,\n",
    "    max_samples=max_samples_train, \n",
    "    device=device\n",
    "    )\n",
    "\n",
    "val_dataset = CandlesDataset(\n",
    "    root_dir=root_dir, \n",
    "    years=years_val, \n",
    "    window_size=window_size,\n",
    "    max_samples=max_samples_val, \n",
    "    device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa57908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T17:12:02.550996Z",
     "iopub.status.busy": "2025-02-09T17:12:02.550675Z",
     "iopub.status.idle": "2025-02-09T17:12:02.554586Z",
     "shell.execute_reply": "2025-02-09T17:12:02.553961Z"
    },
    "papermill": {
     "duration": 0.062055,
     "end_time": "2025-02-09T17:12:02.555661",
     "exception": false,
     "start_time": "2025-02-09T17:12:02.493606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31092ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T17:12:02.669294Z",
     "iopub.status.busy": "2025-02-09T17:12:02.669037Z",
     "iopub.status.idle": "2025-02-09T17:12:02.673968Z",
     "shell.execute_reply": "2025-02-09T17:12:02.673327Z"
    },
    "papermill": {
     "duration": 0.063,
     "end_time": "2025-02-09T17:12:02.675135",
     "exception": false,
     "start_time": "2025-02-09T17:12:02.612135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeEncoder(nn.Module):\n",
    "    def __init__(self, candles_features: int, time_features: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(candles_features, d_model)\n",
    "        self.time2vec = nn.Sequential(\n",
    "            nn.Linear(time_features, 32),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(32, d_model)\n",
    "        )\n",
    "        self.learnable_pe = nn.Parameter(torch.randn(1, 5000, d_model))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, time_features = x[:, :, :5], x[:, :, 5:]\n",
    "        t_emb = self.time2vec(time_features)\n",
    "        x = self.input_proj(x)\n",
    "        x = x + self.learnable_pe[:, :x.size(1), :] + t_emb\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bedbf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T17:12:02.789145Z",
     "iopub.status.busy": "2025-02-09T17:12:02.788903Z",
     "iopub.status.idle": "2025-02-09T17:12:02.793017Z",
     "shell.execute_reply": "2025-02-09T17:12:02.792324Z"
    },
    "papermill": {
     "duration": 0.062331,
     "end_time": "2025-02-09T17:12:02.794094",
     "exception": false,
     "start_time": "2025-02-09T17:12:02.731763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model: int, nhead: int, encoder_layers: int):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, nhead, batch_first=True),\n",
    "            num_layers=encoder_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x).mean(dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a290b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T17:12:02.907707Z",
     "iopub.status.busy": "2025-02-09T17:12:02.907470Z",
     "iopub.status.idle": "2025-02-09T17:12:02.912381Z",
     "shell.execute_reply": "2025-02-09T17:12:02.911677Z"
    },
    "papermill": {
     "duration": 0.06372,
     "end_time": "2025-02-09T17:12:02.913719",
     "exception": false,
     "start_time": "2025-02-09T17:12:02.849999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CandleTransformer(nn.Module):\n",
    "    def __init__(self, heads: int, encoder_layers: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.time_enc = TimeEncoder(candles_features=5, time_features=3, d_model=d_model)\n",
    "        self.transformer = Transformer(d_model=d_model, nhead=heads, encoder_layers=encoder_layers)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(d_model, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 5)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        # prices: [B, 180, 5] (OHLCV)\n",
    "        # indicators: [B, 180, 4]\n",
    "        # time_feats: [B, 180, 3]\n",
    "        \"\"\"\n",
    "        x = self.time_enc(x)\n",
    "        trans_out = self.transformer(x)\n",
    "        out = self.out(trans_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265485d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T17:12:03.033175Z",
     "iopub.status.busy": "2025-02-09T17:12:03.032975Z",
     "iopub.status.idle": "2025-02-09T17:12:03.036370Z",
     "shell.execute_reply": "2025-02-09T17:12:03.035775Z"
    },
    "papermill": {
     "duration": 0.065777,
     "end_time": "2025-02-09T17:12:03.037497",
     "exception": false,
     "start_time": "2025-02-09T17:12:02.971720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def direction_accuracy(pred, true):\n",
    "    direction_pred = torch.sign(pred[:, 1] - pred[:, 0]) # open - close\n",
    "    direction_true = torch.sign(true[:, 1] - true[:, 0])\n",
    "    return (direction_pred == direction_true).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9b94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T17:12:03.150205Z",
     "iopub.status.busy": "2025-02-09T17:12:03.150008Z",
     "iopub.status.idle": "2025-02-09T17:12:03.359547Z",
     "shell.execute_reply": "2025-02-09T17:12:03.358690Z"
    },
    "papermill": {
     "duration": 0.268082,
     "end_time": "2025-02-09T17:12:03.361593",
     "exception": false,
     "start_time": "2025-02-09T17:12:03.093511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR_START = 1e-4\n",
    "LR_MAX = 1e-4\n",
    "LR_MIN = 1e-7\n",
    "LR_RAMPUP_EPOCHS = 0\n",
    "LR_SUSTAIN_EPOCHS = 2\n",
    "\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        decay_total_epochs = max_epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n",
    "        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n",
    "        phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "        cosine_decay = 0.5 * (1 + math.cos(phase))\n",
    "        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n",
    "    return lr / LR_START\n",
    "# cosine sheduler\n",
    "\n",
    "rng = [i for i in range(max_epoch)]\n",
    "lr_y = [lr_lambda(x) for x in rng]\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(rng, lr_y, '-o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e8ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T17:12:03.478062Z",
     "iopub.status.busy": "2025-02-09T17:12:03.477759Z",
     "iopub.status.idle": "2025-02-09T17:12:03.648704Z",
     "shell.execute_reply": "2025-02-09T17:12:03.647982Z"
    },
    "papermill": {
     "duration": 0.230191,
     "end_time": "2025-02-09T17:12:03.650382",
     "exception": false,
     "start_time": "2025-02-09T17:12:03.420191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_mse_loss(\n",
    "        pred, \n",
    "        target, \n",
    "        weights=torch.tensor([1.0, 1.0, 0.7, 0.7, 0.2]).to(device)\n",
    "        ):\n",
    "    return (weights * (pred - target) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9bb5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T17:12:03.766783Z",
     "iopub.status.busy": "2025-02-09T17:12:03.766487Z",
     "iopub.status.idle": "2025-02-09T17:12:07.214426Z",
     "shell.execute_reply": "2025-02-09T17:12:07.213748Z"
    },
    "papermill": {
     "duration": 3.507808,
     "end_time": "2025-02-09T17:12:07.216037",
     "exception": false,
     "start_time": "2025-02-09T17:12:03.708229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CandleTransformer(\n",
    "    heads=heads,\n",
    "    encoder_layers=encoder_layers, \n",
    "    d_model=d_model,\n",
    "    ).to(device=device)\n",
    "\n",
    "criterion = weighted_mse_loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da6e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T17:12:07.333783Z",
     "iopub.status.busy": "2025-02-09T17:12:07.333320Z",
     "iopub.status.idle": "2025-02-09T18:44:49.206171Z",
     "shell.execute_reply": "2025-02-09T18:44:49.204906Z"
    },
    "papermill": {
     "duration": 5561.933484,
     "end_time": "2025-02-09T18:44:49.207906",
     "exception": false,
     "start_time": "2025-02-09T17:12:07.274422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "dir_accuracies = []\n",
    "current_epoch = 0\n",
    "\n",
    "if is_preload:\n",
    "    checkpoint = torch.load(model_path, weights_only=True)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    current_epoch = checkpoint['epoch']\n",
    "    train_losses = checkpoint['train_losses']\n",
    "    val_losses = checkpoint['val_losses']\n",
    "    dir_accuracies = checkpoint['dir_accuracies']\n",
    "    print('Preload model')\n",
    "\n",
    "for epoch in range(current_epoch, max_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for features, targets, _, _  in tqdm(train_loader, desc=f\"Train Epoch {epoch + 1}\"):\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * features.size(0)\n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    for features, targets, _ , _ in tqdm(val_loader, desc=f\"Validation Epoch {epoch + 1}\"):\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "        outputs = model(features)\n",
    "        val_running_loss += criterion(outputs, targets).item() * features.size(0)\n",
    "        all_preds.append(outputs.detach().cpu())\n",
    "        all_targets.append(targets.detach().cpu())\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    val_loss = val_running_loss / len(val_dataset)\n",
    "\n",
    "    dir_accuracy = direction_accuracy(all_preds, all_targets)\n",
    "    dir_accuracies.append(dir_accuracy)\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'dir_accuracies': dir_accuracies\n",
    "        }, os.path.join(model_dir, f'baseline_{epoch}.tar'))\n",
    "    if len(val_losses) == 0 or val_loss < min(val_losses):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'dir_accuracies': dir_accuracies\n",
    "            }, os.path.join(model_dir, f'best.tar'))\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step()\n",
    "    print(f'LR: {current_lr:.4e}')\n",
    "    print(f\"Epoch {epoch+1}/{max_epoch}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\\n\")\n",
    "    print(f\"Val direction Accuracy: {dir_accuracy:.4f}\\n\")\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    dir_accuracies.append(dir_accuracy)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4be03f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T18:44:50.861820Z",
     "iopub.status.busy": "2025-02-09T18:44:50.861447Z",
     "iopub.status.idle": "2025-02-09T18:44:50.866425Z",
     "shell.execute_reply": "2025-02-09T18:44:50.865668Z"
    },
    "papermill": {
     "duration": 0.808778,
     "end_time": "2025-02-09T18:44:50.867664",
     "exception": false,
     "start_time": "2025-02-09T18:44:50.058886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Min validation loss: ', min(val_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c6d32",
   "metadata": {
    "papermill": {
     "duration": 0.811705,
     "end_time": "2025-02-09T18:44:52.520439",
     "exception": false,
     "start_time": "2025-02-09T18:44:51.708734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "record: 1.017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b365e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T18:44:54.157142Z",
     "iopub.status.busy": "2025-02-09T18:44:54.156667Z",
     "iopub.status.idle": "2025-02-09T18:44:55.100813Z",
     "shell.execute_reply": "2025-02-09T18:44:55.100029Z"
    },
    "papermill": {
     "duration": 1.711042,
     "end_time": "2025-02-09T18:44:55.102448",
     "exception": false,
     "start_time": "2025-02-09T18:44:53.391406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_counter = 10\n",
    "dataloader = DataLoader(val_dataset, batch_size=1, num_workers=num_workers, shuffle=True)\n",
    "counter = 0\n",
    "for features, targets, std, mean in dataloader:\n",
    "    features, targets, std, mean = features.to(device), targets.to(device), std.to(device), mean.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(features).detach()\n",
    "    print(f\"Target: \", (targets*std+mean).cpu())\n",
    "    print(f\"Output: \", (outputs*std+mean).cpu())\n",
    "    print()\n",
    "    counter += 1\n",
    "    if counter == max_counter:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6607307,
     "sourceId": 10670477,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6934.28656,
   "end_time": "2025-02-09T18:44:58.664370",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-09T16:49:24.377810",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
